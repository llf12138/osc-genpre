{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8824c05-e893-4636-baee-b367d92f0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "data = pd.read_csv(\"data_A_gen.csv\")\n",
    "smiles_list = data['smiles'].tolist()\n",
    "\n",
    "special_tokens = [\"@\", \"+\"]\n",
    "atom_symbols = set()\n",
    "\n",
    "for smiles in smiles_list:\n",
    "    i = 0\n",
    "    while i < len(smiles):\n",
    "        if smiles[i] == \"[\":\n",
    "            j = smiles.find(\"]\", i)\n",
    "            if j != -1:\n",
    "                atom_symbols.add(smiles[i : j + 1])\n",
    "                i = j + 1\n",
    "            else:\n",
    "                raise ValueError(f\"Unmatched bracket: {smiles}\")\n",
    "        elif i + 1 < len(smiles) and smiles[i : i + 2] in [\"Cl\", \"Br\"]:\n",
    "            atom_symbols.add(smiles[i : i + 2])\n",
    "            i += 2\n",
    "        else:\n",
    "            atom_symbols.add(smiles[i])\n",
    "            i += 1\n",
    "\n",
    "vocab = sorted(list(atom_symbols)) + special_tokens\n",
    "vocab_dict = {char: idx for idx, char in enumerate(vocab)}\n",
    "reverse_vocab_dict = {idx: char for char, idx in vocab_dict.items()}\n",
    "\n",
    "vocab_complete = {\"char_to_idx\": vocab_dict, \"idx_to_char\": reverse_vocab_dict}\n",
    "torch.save(vocab_complete, \"vocab.pt\")\n",
    "\n",
    "max_len = max(len(smiles) for smiles in smiles_list) + 1\n",
    "\n",
    "def encode_smiles(smiles, vocab_dict, max_len):\n",
    "    encoded = [vocab_dict[\"@\"]]\n",
    "    i = 0\n",
    "    while i < len(smiles):\n",
    "        if smiles[i] == \"[\":\n",
    "            j = smiles.find(\"]\", i)\n",
    "            if j != -1:\n",
    "                token = smiles[i : j + 1]\n",
    "                if token not in vocab_dict:\n",
    "                    raise ValueError(f\"Unknown token: {token}\")\n",
    "                encoded.append(vocab_dict[token])\n",
    "                i = j + 1\n",
    "            else:\n",
    "                raise ValueError(f\"Unmatched bracket: {smiles}\")\n",
    "        elif i + 1 < len(smiles) and smiles[i : i + 2] in vocab_dict:\n",
    "            token = smiles[i : i + 2]\n",
    "            encoded.append(vocab_dict[token])\n",
    "            i += 2\n",
    "        else:\n",
    "            token = smiles[i]\n",
    "            if token not in vocab_dict:\n",
    "                raise ValueError(f\"Unknown token: {token}\")\n",
    "            encoded.append(vocab_dict[token])\n",
    "            i += 1\n",
    "    while len(encoded) < max_len:\n",
    "        encoded.append(vocab_dict[\"+\"])\n",
    "    return encoded\n",
    "\n",
    "encoded_smiles = [encode_smiles(smiles, vocab_dict, max_len) for smiles in smiles_list]\n",
    "\n",
    "smiles_tensor = torch.tensor(encoded_smiles, dtype=torch.long)\n",
    "\n",
    "total_samples = len(smiles_tensor)\n",
    "indices = list(range(total_samples))\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = int(0.1 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size : train_size + val_size]\n",
    "test_indices = indices[train_size + val_size :]\n",
    "\n",
    "train_tensor = smiles_tensor[train_indices]\n",
    "val_tensor = smiles_tensor[val_indices]\n",
    "test_tensor = smiles_tensor[test_indices]\n",
    "\n",
    "torch.save({\n",
    "    \"train\": train_tensor,\n",
    "    \"val\": val_tensor,\n",
    "    \"test\": test_tensor\n",
    "}, \"smiles.pt\")\n",
    "\n",
    "print(\"Vocabulary content:\")\n",
    "print(vocab_complete)\n",
    "print(\"\\nTraining set size:\", train_tensor.size(0))\n",
    "print(\"Validation set size:\", val_tensor.size(0))\n",
    "print(\"Test set size:\", test_tensor.size(0))\n",
    "print(\"\\nLast molecule encoding (test set):\")\n",
    "print(test_tensor[-1].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
